{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd4afd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.14.12-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.15.0,>=0.14.12 (from llama-index)\n",
      "  Downloading llama_index_core-0.14.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.6.12-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting aiohttp<4,>=3.8.6 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading aiosqlite-0.22.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: httpx in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.28.1)\n",
      "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading llama_index_workflows-2.11.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting numpy (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading pillow-12.0.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: platformdirs in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (4.3.7)\n",
      "Collecting pydantic>=2.8.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.32.4)\n",
      "Collecting setuptools>=80.9.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading sqlalchemy-2.0.45-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.7.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm<5,>=4.66.1 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading wrapt-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (75 kB)\n",
      "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.1.6)\n",
      "Collecting openai>=1.1.0 (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index)\n",
      "  Downloading openai-2.14.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.4)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
      "Collecting pandas<3,>=2.0.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading pandas-2.3.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (91 kB)\n",
      "Collecting pypdf<7,>=6.1.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading pypdf-6.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.5)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (4.7.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index)\n",
      "  Downloading jiter-0.12.0-cp310-cp310-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading wrapt-1.17.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.88-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.88 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.88-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting click<9,>=8.1.7 (from llama-cloud-services>=0.6.88->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.87-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.87 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.87-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.86-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.86 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.86-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.85-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.85 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.85-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.84-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting llama-cloud-services>=0.6.84 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.84-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.83-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.82 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.83-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading llama_cloud_services-0.6.82-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.82-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv<2,>=1.0.1 (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index)\n",
      "  Downloading regex-2025.11.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (2.5.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading greenlet-3.3.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.12->llama-index) (25.0)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.0.2)\n",
      "Downloading llama_index-0.14.12-py3-none-any.whl (7.5 kB)\n",
      "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.14.12-py3-none-any.whl (11.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m111.4 kB/s\u001b[0m  \u001b[33m0:01:55\u001b[0mm0:00:02\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.2-cp310-cp310-macosx_10_9_x86_64.whl (493 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_llms_openai-0.6.12-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_readers_file-0.5.6-py3-none-any.whl (51 kB)\n",
      "Downloading llama_index_workflows-2.11.6-py3-none-any.whl (92 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-macosx_10_9_x86_64.whl (44 kB)\n",
      "Downloading openai-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m193.3 kB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp310-cp310-macosx_10_12_x86_64.whl (316 kB)\n",
      "Downloading pandas-2.3.3-cp310-cp310-macosx_10_9_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m181.6 kB/s\u001b[0m  \u001b[33m0:01:20\u001b[0mm0:00:02\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-macosx_10_12_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m146.4 kB/s\u001b[0m  \u001b[33m0:00:14\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-6.5.0-py3-none-any.whl (329 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-macosx_10_9_x86_64.whl (93 kB)\n",
      "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-macosx_10_9_x86_64.whl (49 kB)\n",
      "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
      "Downloading wrapt-1.17.3-cp310-cp310-macosx_10_9_x86_64.whl (38 kB)\n",
      "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
      "Downloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m456.8 kB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m387.2 kB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m205.1 kB/s\u001b[0m  \u001b[33m0:00:32\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp310-cp310-macosx_10_10_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m373.2 kB/s\u001b[0m  \u001b[33m0:00:14\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.4.1-cp310-cp310-macosx_10_9_x86_64.whl (45 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2025.11.3-cp310-cp310-macosx_10_9_x86_64.whl (290 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m222.1 kB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.45-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m469.1 kB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.3.0-cp310-cp310-macosx_11_0_universal2.whl (273 kB)\n",
      "Downloading tiktoken-0.12.0-cp310-cp310-macosx_10_12_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Downloading aiosqlite-0.22.1-py3-none-any.whl (17 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Installing collected packages: striprtf, pytz, filetype, dirtyjson, wrapt, tzdata, typing-extensions, tqdm, tenacity, setuptools, regex, python-dotenv, propcache, pillow, numpy, networkx, mypy-extensions, marshmallow, joblib, jiter, greenlet, fsspec, frozenlist, distro, colorama, click, async-timeout, annotated-types, aiosqlite, aiohappyeyeballs, typing-inspection, typing-inspect, tiktoken, sqlalchemy, pypdf, pydantic-core, pandas, nltk, multidict, griffe, deprecated, aiosignal, yarl, pydantic, dataclasses-json, openai, ollama, llama-index-instrumentation, llama-cloud, banks, aiohttp, llama-index-workflows, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/62\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.12.2━━━━━\u001b[0m \u001b[32m 5/62\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.12.2:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/62\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.12.2━━━━━━━━━━━\u001b[0m \u001b[32m 6/62\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/62\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: setuptools 78.1.1━━━━━━━━━━━━\u001b[0m \u001b[32m 6/62\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling setuptools-78.1.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/62\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled setuptools-78.1.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/62\u001b[0m [setuptools]ns]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62/62\u001b[0m [llama-index]\u001b[0m [llama-cloud-services]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 aiosqlite-0.22.1 annotated-types-0.7.0 async-timeout-5.0.1 banks-2.2.0 click-8.3.1 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 filetype-1.2.0 frozenlist-1.8.0 fsspec-2025.12.0 greenlet-3.3.0 griffe-1.15.0 jiter-0.12.0 joblib-1.5.3 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.12 llama-index-cli-0.5.3 llama-index-core-0.14.12 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-openai-0.6.12 llama-index-readers-file-0.5.6 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.11.6 llama-parse-0.6.54 marshmallow-3.26.2 multidict-6.7.0 mypy-extensions-1.1.0 networkx-3.4.2 nltk-3.9.2 numpy-2.2.6 ollama-0.6.1 openai-2.14.0 pandas-2.3.3 pillow-12.0.0 propcache-0.4.1 pydantic-2.12.5 pydantic-core-2.41.5 pypdf-6.5.0 python-dotenv-1.2.1 pytz-2025.2 regex-2025.11.3 setuptools-80.9.0 sqlalchemy-2.0.45 striprtf-0.0.26 tenacity-9.1.2 tiktoken-0.12.0 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.2 tzdata-2025.3 wrapt-1.17.3 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install llama-index ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5486a9-5e5a-4846-987a-2807c4848576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llmsherpa\n",
      "  Downloading llmsherpa-0.1.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: urllib3 in /Users/Rainy/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages (from llmsherpa) (2.5.0)\n",
      "Downloading llmsherpa-0.1.4-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: llmsherpa\n",
      "Successfully installed llmsherpa-0.1.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install llmsherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92767ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the table, Google's operating margin for Q1 2024 was 32%. This is indicated in the \"Operating income\" and \"Operating margin\" rows of the table.\n",
      "To find the percentage of Net income is of the Revenues, you can divide the Net Income by the Revenues and then multiply by 100.\n",
      "\n",
      "For Q1 2024:\n",
      "\n",
      "Net Income = $23,662\n",
      "Revenues = $80,539\n",
      "\n",
      "Percentage = ($23,662 ÷ $80,539) x 100 = 29.5%\n",
      "\n",
      "Therefore, the percentage of Net income is approximately 29.5% of the Revenues for Q1 2024.\n"
     ]
    }
   ],
   "source": [
    "#!python3 query_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679f6ba-7eb6-489d-8018-8f3ec48f45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89173a-1799-4241-a8c5-e86e892f4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmsherpa.readers import LayoutPDFReader\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Document, ServiceContext, Settings\n",
    "#from llama_index.embeddings.huggingface import HuggingFaceEmbedding# no need\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "# Initialize LLm\n",
    "llm = Ollama(model=\"llama3\", request_timeout=60.0)\n",
    "\n",
    "llmsherpa_api_url = \"http://localhost:5010/api/parseDocument?renderFormat=all\"\n",
    "pdf_url = \"https://s206.q4cdn.com/479360582/files/doc_financials/2024/q1/2024q1-alphabet-earnings-release-pdf.pdf\"\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "\n",
    "# Read PDF\n",
    "doc = pdf_reader.read_pdf(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9ae58-30f1-4773-807e-5d75c1534289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aae65f9-a021-4a98-adfc-ebfeaf674454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the table, Google's operating margin for 2024 was 32%. This is based on the \"Operating income\" and \"Revenues\" figures provided in the table.\n",
      "To calculate the percentage of Net income to Revenues, we can use the figures from Q1 2024:\n",
      "\n",
      "Revenues: $80,539\n",
      "Net Income: $23,662\n",
      "\n",
      "Percentage = (Net Income / Revenues) x 100%\n",
      "\n",
      "Percentage = ($23,662 / $80,539) x 100% ≈ 29.5%\n",
      "\n",
      "So, Net income is approximately 29.5% of the Revenues.\n"
     ]
    }
   ],
   "source": [
    "# Get data from the Section by Title\n",
    "selected_section = None\n",
    "for section in doc.sections():\n",
    "    if 'Q1 2024 Financial Highlights' in section.title:\n",
    "        selected_section = section\n",
    "        break\n",
    "\n",
    "# Convert the output in HTML format\n",
    "context = selected_section.to_html(include_children=True, recurse=True)\n",
    "question = \"What was Google's operating margin for 2024\"\n",
    "resp = llm.complete(\n",
    "    f\"read this table and answer question: {question}:\\n{context}\")\n",
    "print(resp.text)\n",
    "\n",
    "question = \"What % Net income is of the Revenues?\"\n",
    "resp = llm.complete(\n",
    "    f\"read this table and answer question: {question}:\\n{context}\")\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92500e50-cc4d-4912-9ecd-685c8f39ca66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Task a: Loading all sections with tables...\n",
      "============================================================\n",
      "Found table in section: Q1 2024 Financial Highlights (unaudited)\n",
      "Found table in section: Revenues, Traffic Acquisition Costs (TAC), and Number of Employees\n",
      "Found table in section: Segment Operating Results\n",
      "Found table in section: Employee Severance and Related Charges\n",
      "Found table in section: Contact\n",
      "Found table in section: (In millions, except par value per share amounts)\n",
      "Found table in section: Quarter Ended March 31, 2023 2024\n",
      "Found table in section: Operating activities\n",
      "Found table in section: Segment Results\n",
      "Found table in section: Other Income (Expense), Net\n",
      "Found table in section: Revenues by Geography\n",
      "Found table in section: Quarter Ended March 31, 2024\n",
      "Found table in section: Total Revenues — Prior Year Comparative Periods\n",
      "Found table in section: Quarter Ended March 31,\n",
      "\n",
      "Found 14 sections with tables\n",
      "\n",
      "============================================================\n",
      "Task b: Testing reasoning capabilities...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "[LOOKUP] What was Google's operating margin for Q1 2024?\n",
      "Expected behavior: 应该返回32%\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {socket\u001b[38;5;241m.\u001b[39mtimeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 124\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask b: Testing reasoning capabilities...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_reasoning_capabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43msections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# 总结\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 97\u001b[0m, in \u001b[0;36mtest_reasoning_capabilities\u001b[0;34m(sections_with_tables)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected behavior: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mquery_all_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msections_with_tables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLLM Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m: test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m: answer,\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m'\u001b[39m: test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    105\u001b[0m })\n",
      "Cell \u001b[0;32mIn[16], line 37\u001b[0m, in \u001b[0;36mquery_all_tables\u001b[0;34m(question, sections_with_tables)\u001b[0m\n\u001b[1;32m     23\u001b[0m     combined_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Section: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sections_with_tables\n\u001b[1;32m     26\u001b[0m     ])\n\u001b[1;32m     28\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mBased on the following tables from a financial report, answer this question:\u001b[39m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;124mPlease provide a clear answer. If calculation is needed, show your steps.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/llama_index/core/llms/callbacks.py:435\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    427\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    428\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m     },\n\u001b[1;32m    433\u001b[0m )\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    437\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    438\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    439\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    440\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    441\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/llama_index/llms/ollama/base.py:657\u001b[0m, in \u001b[0;36mOllama.complete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;129m@llm_completion_callback\u001b[39m()\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, formatted: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    656\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_to_completion_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/llama_index/core/base/llms/generic_utils.py:184\u001b[0m, in \u001b[0;36mchat_to_completion_decorator.<locals>.wrapper\u001b[0;34m(prompt, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# normalize input\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     messages \u001b[38;5;241m=\u001b[39m prompt_to_messages(prompt)\n\u001b[0;32m--> 184\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# normalize output\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_response_to_completion_response(chat_response)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/llama_index/core/llms/callbacks.py:175\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    167\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    168\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     },\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    178\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    179\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    180\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    181\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/llama_index/llms/ollama/base.py:395\u001b[0m, in \u001b[0;36mOllama.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m think \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthink\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthinking\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjson_mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 395\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mollama_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(response)\n\u001b[1;32m    408\u001b[0m blocks: List[TextBlock \u001b[38;5;241m|\u001b[39m ThinkingBlock \u001b[38;5;241m|\u001b[39m ToolCallBlock] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/ollama/_client.py:365\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, think, logprobs, top_logprobs, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    319\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    320\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/ollama/_client.py:189\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/ollama/_client.py:129\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    128\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpx/_transports/default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhttpcore\u001b[39;00m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out"
     ]
    }
   ],
   "source": [
    "def get_all_sections_with_tables(doc):\n",
    "    sections_with_tables = []\n",
    "    for section in doc.sections():\n",
    "        html = section.to_html(include_children=True, recurse=True)\n",
    "        if '<table' in html.lower():\n",
    "            sections_with_tables.append({\n",
    "                'title': section.title,\n",
    "                'html': html\n",
    "            })\n",
    "            print(f\"Found table in section: {section.title}\")\n",
    "    return sections_with_tables\n",
    "\n",
    "\n",
    "def query_all_tables(question: str, sections_with_tables: list) -> str:\n",
    "    combined_context = \"\\n\\n\".join([\n",
    "        f\"=== Section: {s['title']} ===\\n{s['html']}\" \n",
    "        for s in sections_with_tables\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Based on the following tables from a financial report, answer this question:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Tables:\n",
    "{combined_context}\n",
    "\n",
    "Please provide a clear answer. If calculation is needed, show your steps.\"\"\"\n",
    "    \n",
    "    resp = llm.complete(prompt)\n",
    "    return resp.text\n",
    "\n",
    "\n",
    "# ========== Task b:  ==========\n",
    "\n",
    "def test_reasoning_capabilities(sections_with_tables: list):\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"question\": \"What was Google's operating margin for Q1 2024?\",\n",
    "            \"type\": \"lookup\",\n",
    "            \"expected\": \"应该返回32%\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"question\": \"What is the sum of Revenues for Q1 2023 and Q1 2024?\",\n",
    "            \"type\": \"addition\",\n",
    "            \"expected\": \"应该是 69,787 + 80,539 = 150,326\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"question\": \"How much did Operating income increase from Q1 2023 to Q1 2024?\",\n",
    "            \"type\": \"subtraction\",\n",
    "            \"expected\": \"25,472 - 17,415 = 8,057\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"question\": \"What percentage is Net income of Revenues for Q1 2024?\",\n",
    "            \"type\": \"percentage\",\n",
    "            \"expected\": \"23,662 / 80,539 ≈ 29.4%\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"question\": \"Which metric showed the largest percentage increase from 2023 to 2024?\",\n",
    "            \"type\": \"comparison\",\n",
    "            \"expected\": \"需要比较多个指标的增长率\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"question\": \"If the revenue growth rate from Q1 2023 to Q1 2024 continues, what would be the projected Q1 2025 revenue?\",\n",
    "            \"type\": \"projection\",\n",
    "            \"expected\": \"需要计算增长率(15%)然后应用\"\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for test in test_cases:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[{test['type'].upper()}] {test['question']}\")\n",
    "        print(f\"Expected behavior: {test['expected']}\")\n",
    "        \n",
    "        answer = query_all_tables(test['question'], sections_with_tables)\n",
    "        print(f\"\\nLLM Answer: {answer}\")\n",
    "        \n",
    "        results.append({\n",
    "            'type': test['type'],\n",
    "            'question': test['question'],\n",
    "            'answer': answer,\n",
    "            'expected': test['expected']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Task a\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Task a: Loading all sections with tables...\")\n",
    "    print(\"=\" * 60)\n",
    "    sections = get_all_sections_with_tables(doc)\n",
    "    print(f\"\\nFound {len(sections)} sections with tables\")\n",
    "    \n",
    "    # Task b\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Task b: Testing reasoning capabilities...\")\n",
    "    print(\"=\" * 60)\n",
    "    results = test_reasoning_capabilities(sections)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY: LLM Reasoning Capabilities\")\n",
    "    print(\"=\" * 60)\n",
    "    for r in results:\n",
    "        print(f\"- {r['type']}: Check if answer is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "960c84d7-e19f-4c34-94b3-2baeb9a40d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1: Generating section summaries...\n",
      "============================================================\n",
      "Section: Q1 2024 Financial Highlights (unaudited)\n",
      "Preview: Q1 2024 Financial Highlights (unaudited)...\n",
      "----------------------------------------\n",
      "Section: Revenues, Traffic Acquisition Costs (TAC), and Number of Employees\n",
      "Preview: Revenues, Traffic Acquisition Costs (TAC), and Number of Employees...\n",
      "----------------------------------------\n",
      "Section: Segment Operating Results\n",
      "Preview: Segment Operating Results...\n",
      "----------------------------------------\n",
      "Section: Employee Severance and Related Charges\n",
      "Preview: Employee Severance and Related Charges...\n",
      "----------------------------------------\n",
      "Section: Contact\n",
      "Preview: Contact...\n",
      "----------------------------------------\n",
      "Section: (In millions, except par value per share amounts)\n",
      "Preview: (In millions, except par value per share amounts)...\n",
      "----------------------------------------\n",
      "Section: Quarter Ended March 31, 2023 2024\n",
      "Preview: Quarter Ended March 31, 2023 2024...\n",
      "----------------------------------------\n",
      "Section: Operating activities\n",
      "Preview: Operating activities...\n",
      "----------------------------------------\n",
      "Section: Segment Results\n",
      "Preview: Segment Results...\n",
      "----------------------------------------\n",
      "Section: Other Income (Expense), Net\n",
      "Preview: Other Income (Expense), Net...\n",
      "----------------------------------------\n",
      "Section: Revenues by Geography\n",
      "Preview: Revenues by Geography...\n",
      "----------------------------------------\n",
      "Section: Quarter Ended March 31, 2024\n",
      "Preview: Quarter Ended March 31, 2024...\n",
      "----------------------------------------\n",
      "Section: Total Revenues — Prior Year Comparative Periods\n",
      "Preview: Total Revenues — Prior Year Comparative Periods...\n",
      "----------------------------------------\n",
      "Section: Quarter Ended March 31,\n",
      "Preview: Quarter Ended March 31,...\n",
      "----------------------------------------\n",
      "\n",
      "Found 14 sections with tables\n",
      "\n",
      "============================================================\n",
      "Testing reasoning capabilities...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "[LOOKUP] What was Google's operating margin for Q1 2024?\n",
      "Expected: 32%\n",
      "Selected sections for 'What was Google's operating margin for Q1 2024?':\n",
      "  - Q1 2024 Financial Highlights (unaudited)\n",
      "  - Segment Operating Results\n",
      "\n",
      "LLM Answer: Based on the provided tables from Google's financial report, the operating margin for Q1 2024 can be found in the \"Q1 2024 Financial Highlights\" table.\n",
      "\n",
      "The operating income and revenue figures for Q1 2024 are:\n",
      "\n",
      "* Operating income (loss): $25,472\n",
      "* Revenues: $80,539\n",
      "\n",
      "To calculate the operating margin, we need to divide the operating income by revenues and multiply by 100:\n",
      "\n",
      "Operating Margin = ($25,472 / $80,539) x 100\n",
      "= 31.54%\n",
      "\n",
      "Therefore, Google's operating margin for Q1 2024 is approximately 31.54%.\n",
      "\n",
      "============================================================\n",
      "[ADDITION] What is the sum of Google Services revenue and Google Cloud revenue for Q1 2024?\n",
      "Expected: 70,398 + 9,574 = 79,972\n",
      "Selected sections for 'What is the sum of Google Services revenue and Google Cloud revenue for Q1 2024?':\n",
      "  - Q1 2024 Financial Highlights (unaudited)\n",
      "  - Segment Results\n",
      "\n",
      "LLM Answer: To find the sum of Google Services revenue and Google Cloud revenue for Q1 2024, we can simply add the two values together:\n",
      "\n",
      "Google Services revenue for Q1 2024: $70,398\n",
      "Google Cloud revenue for Q1 2024: $9,574\n",
      "\n",
      "Total = $70,398 + $9,574 = $79,972\n",
      "\n",
      "============================================================\n",
      "[PERCENTAGE] What percentage of total revenues comes from Google Cloud in Q1 2024?\n",
      "Expected: 9,574 / 80,539 ≈ 11.9%\n",
      "Selected sections for 'What percentage of total revenues comes from Google Cloud in Q1 2024?':\n",
      "  - Segment Results\n",
      "  - Revenues by Geography\n",
      "\n",
      "LLM Answer: To find the percentage of total revenues that comes from Google Cloud in Q1 2024, we need to calculate the revenue from Google Cloud and then divide it by the total revenue.\n",
      "\n",
      "From the table \"Segment Results\", we can see that the revenue from Google Cloud is $9,574 million in Q1 2024.\n",
      "\n",
      "The total revenue is $80,539 million in Q1 2024.\n",
      "\n",
      "To find the percentage, we need to divide the revenue from Google Cloud by the total revenue and multiply by 100:\n",
      "\n",
      "($9,574 million / $80,539 million) x 100 = 11.88%\n",
      "\n",
      "So, approximately 11.88% of total revenues come from Google Cloud in Q1 2024.\n",
      "\n",
      "============================================================\n",
      "[COMPARISON] Which segment had the highest operating income in Q1 2024?\n",
      "Expected: Google Services ($27,897 million)\n",
      "Selected sections for 'Which segment had the highest operating income in Q1 2024?':\n",
      "  - Q1 2024 Financial Highlights (unaudited)\n",
      "  - Segment Operating Results\n",
      "\n",
      "LLM Answer: Based on the provided tables, we can find the operating income for each segment in Q1 2024:\n",
      "\n",
      "* Google Services: $27,897\n",
      "* Google Cloud: $900\n",
      "* Other Bets: -$1,020\n",
      "* Alphabet-level activities: -$2,305\n",
      "\n",
      "The total operating income is $25,472.\n",
      "\n",
      "To determine which segment had the highest operating income, we can simply compare the values:\n",
      "\n",
      "$27,897 (Google Services) > $25,472 (Total operating income) = $900 (Google Cloud) > -$1,020 (Other Bets) > -$2,305 (Alphabet-level activities)\n",
      "\n",
      "Therefore, the answer is: Google Services had the highest operating income in Q1 2024.\n",
      "\n",
      "============================================================\n",
      "[GROWTH] How much did total revenues increase from Q1 2023 to Q1 2024?\n",
      "Expected: 80,539 - 69,787 = 10,752 (about 15% growth)\n",
      "Selected sections for 'How much did total revenues increase from Q1 2023 to Q1 2024?':\n",
      "  - Q1 2024 Financial Highlights (unaudited)\n",
      "  - Total Revenues — Prior Year Comparative Periods\n",
      "\n",
      "LLM Answer: To find the total revenue increase from Q1 2023 to Q1 2024, we can subtract the Q1 2023 total revenue from the Q1 2024 total revenue:\n",
      "\n",
      "Total Revenue (Q1 2024) - Total Revenue (Q1 2023)\n",
      "= $80,539 - $69,787\n",
      "= $10,752\n",
      "\n",
      "So, the total revenues increased by $10,752 from Q1 2023 to Q1 2024.\n"
     ]
    }
   ],
   "source": [
    "#Step 0: create summary for tables\n",
    "\n",
    "def generate_section_summaries(doc):\n",
    "    \"\"\"\n",
    "    generate summary for each table\n",
    "    \"\"\"\n",
    "    sections_info = []\n",
    "    \n",
    "    for section in doc.sections():\n",
    "        html = section.to_html(include_children=True, recurse=True)\n",
    "        if '<table' not in html.lower():\n",
    "            continue\n",
    "        \n",
    "        text_preview = section.to_text()[:500]  # first 500 chars\n",
    "        \n",
    "        sections_info.append({\n",
    "            'title': section.title,\n",
    "            'preview': text_preview,\n",
    "            'html': html,  # save the html\n",
    "        })\n",
    "        \n",
    "        print(f\"Section: {section.title}\")\n",
    "        print(f\"Preview: {text_preview[:100]}...\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    return sections_info\n",
    "\n",
    "\n",
    "#Step 1, choose related content\n",
    "\n",
    "def select_relevant_sections(question: str, sections_info: list, max_sections: int = 2) -> list:\n",
    "    sections_list = \"\\n\".join([\n",
    "        f\"{i+1}. {s['title']}: {s['preview'][:150]}...\" \n",
    "        for i, s in enumerate(sections_info)\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Given the following sections from a financial report, which sections are most relevant to answer this question?\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Available sections:\n",
    "{sections_list}\n",
    "\n",
    "Return ONLY the section numbers (e.g., \"1, 3\") that are most relevant. Return at most {max_sections} sections.\n",
    "If none are relevant, return \"none\".\n",
    "\n",
    "IMPORTANT RULES:\n",
    "1. If the question asks for a specific metric (like \"operating margin\", \"revenue\", \"EPS\"), \n",
    "   look for sections that DIRECTLY contain that exact metric, not sections where you would need to calculate it.\n",
    "2. \"Financial Highlights\" sections usually contain summary metrics directly.\n",
    "3. \"Segment Results\" sections contain breakdowns by business segment.\n",
    "4. Choose sections that would give the MOST DIRECT answer.\n",
    "\n",
    "Answer (just the numbers):\"\"\"\n",
    "    \n",
    "    resp = llm.complete(prompt)\n",
    "    response_text = resp.text.strip()\n",
    "    \n",
    "    selected_indices = []\n",
    "    if response_text.lower() != \"none\":\n",
    "        import re\n",
    "        numbers = re.findall(r'\\d+', response_text)\n",
    "        for num in numbers:\n",
    "            idx = int(num) - 1  # 转换为0-indexed\n",
    "            if 0 <= idx < len(sections_info):\n",
    "                selected_indices.append(idx)\n",
    "    \n",
    "    # 返回选中的sections\n",
    "    selected = [sections_info[i] for i in selected_indices[:max_sections]]\n",
    "    \n",
    "    print(f\"Selected sections for '{question}':\")\n",
    "    for s in selected:\n",
    "        print(f\"  - {s['title']}\")\n",
    "    \n",
    "    return selected\n",
    "\n",
    "\n",
    "#Step 2.answer\n",
    "\n",
    "def query_tables(question: str, selected_sections: list) -> str:\n",
    "    if not selected_sections:\n",
    "        return \"No relevant sections found for this question.\"\n",
    "    \n",
    "    combined_context = \"\\n\\n\".join([\n",
    "        f\"=== {s['title']} ===\\n{s['html']}\" \n",
    "        for s in selected_sections\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Based on the following tables from a financial report, answer this question:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Tables:\n",
    "{combined_context}\n",
    "\n",
    "Please provide a clear answer. If calculation is needed, show your work step by step.\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    resp = llm.complete(prompt)\n",
    "    return resp.text\n",
    "\n",
    "\n",
    "# =========test ==========\n",
    "\n",
    "def test_reasoning_capabilities(sections_info: list):\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"question\": \"What was Google's operating margin for Q1 2024?\",\n",
    "            \"type\": \"lookup\",\n",
    "            \"expected\": \"32%\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the sum of Google Services revenue and Google Cloud revenue for Q1 2024?\",\n",
    "            \"type\": \"addition\",\n",
    "            \"expected\": \"70,398 + 9,574 = 79,972\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What percentage of total revenues comes from Google Cloud in Q1 2024?\",\n",
    "            \"type\": \"percentage\",\n",
    "            \"expected\": \"9,574 / 80,539 ≈ 11.9%\"\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"question\": \"Which segment had the highest operating income in Q1 2024?\",\n",
    "            \"type\": \"comparison\",\n",
    "            \"expected\": \"Google Services ($27,897 million)\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How much did total revenues increase from Q1 2023 to Q1 2024?\",\n",
    "            \"type\": \"growth\",\n",
    "            \"expected\": \"80,539 - 69,787 = 10,752 (about 15% growth)\"\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for test in test_cases:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[{test['type'].upper()}] {test['question']}\")\n",
    "        print(f\"Expected: {test['expected']}\")\n",
    "        \n",
    "\n",
    "        selected = select_relevant_sections(test['question'], sections_info)\n",
    "        \n",
    "\n",
    "        answer = query_tables(test['question'], selected)\n",
    "        print(f\"\\nLLM Answer: {answer}\")\n",
    "        \n",
    "        results.append({\n",
    "            'type': test['type'],\n",
    "            'question': test['question'],\n",
    "            'answer': answer,\n",
    "            'expected': test['expected'],\n",
    "            'sections_used': [s['title'] for s in selected]\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Step 1: Generating section summaries...\")\n",
    "    print(\"=\" * 60)\n",
    "    sections_info = generate_section_summaries(doc)\n",
    "    print(f\"\\nFound {len(sections_info)} sections with tables\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Testing reasoning capabilities...\")\n",
    "    print(\"=\" * 60)\n",
    "    results = test_reasoning_capabilities(sections_info)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fded80-47bd-4c9c-ba17-c83522c85b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
